{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3452ec6a-3519-4a14-a9ae-ab8d820f4945",
   "metadata": {},
   "source": [
    "# 对一个数字图片进行GAN训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9fc66-27e3-464e-bd12-344ed26dcc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import random\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1abf3c-f4f2-43ba-892d-0a25186c6cd9",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf4253-0fcb-43ad-a20a-2c88d9c08d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epoch = 1000\n",
    "lr = 2e-4\n",
    "tar_domain = './data'\n",
    "nlen = 100 #噪声的长度\n",
    "kstep = 5 # 小迭代的次数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d671e3-99c2-4e0b-a9b2-d5b8c572c826",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53231354-f946-491a-a88b-64fc0230c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(tar_domain, batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5)\n",
    "    ])\n",
    "    data = datasets.MNIST(root = tar_domain, train = True, transform = transform, download = True)\n",
    "    # data = datasets.ImageFolder(root = tar_domain, transform = transform)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        data, batch_size = batch_size, shuffle = True, drop_last = False)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4ce07-5c89-42e6-ae32-0efea40f5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子，保证每次运行时结果不变\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "targetDataset = load_data(tar_domain, batch_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af4650-395b-4363-b5e2-839d53aaaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试读取\n",
    "imgs, labels = next(iter(targetDataset))\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ee86e-9636-4756-90f8-aee9d3e16cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取前6个图片并显示\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(imgs[i][0], cmap='gray', interpolation='none')#子显示\n",
    "    plt.title(\"Truth value:{}\".format(labels[i]))  #显示title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fa6d5-31ee-4501-b979-96bb077dd14d",
   "metadata": {},
   "source": [
    "## 生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdc9ea-9964-43ee-a422-298d9e5d238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(nn.Linear(100,256),\n",
    "                                  nn.ReLU(0.1),\n",
    "                                  nn.Linear(256,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(512,28*28),\n",
    "                                  nn.Tanh()\n",
    "                                 )\n",
    "    def forward(self, x):    # x表示长度为100的noise输入\n",
    "        img = self.main(x)\n",
    "        img = img.view(-1,28,28,1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9983ca-cc2b-4b87-bc9d-3182d2d4dcef",
   "metadata": {},
   "source": [
    "## 判别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651e273-f764-4813-a9f4-488965221155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(nn.Linear(28*28,512),\n",
    "                                  nn.LeakyReLU(0.1),\n",
    "                                  nn.Linear(512,256),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(256,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38145b9-dc5a-427c-816c-2ee7dbadaf82",
   "metadata": {},
   "source": [
    "## 初始化模型。优化器及损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bd15a-a0ba-4ea9-b745-98f17973a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "Doptimizer = torch.optim.Adam(D.parameters(), lr)\n",
    "Goptimizer = torch.optim.Adam(G.parameters(), lr)\n",
    "\n",
    "# 损失函数\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "# 可以用来保存每次迭代的loss\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "D_prob = []\n",
    "G_prob = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094430bf-c6b3-479d-b889-f6d7770ac440",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ff905-8b74-4f9e-9d51-2a26c88bb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "since = time.time()\n",
    "learnTarget = imgs[0][0]\n",
    "plt.imshow(learnTarget)\n",
    "img = learnTarget.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9a2b8-c603-4dc1-a2e8-ba19158b1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 训练过程\n",
    "for epoch in range(n_epoch):\n",
    "    Dloss = 0\n",
    "    Gloss = 0\n",
    "    real = 0\n",
    "    fake = 0\n",
    "    # 这里的k最大取值是一个超参数\n",
    "    for k in range(kstep):\n",
    "        real = D(img)  # 是一个概率\n",
    "        realDloss = loss(real, torch.ones_like(real))\n",
    "        # -log(p(x))\n",
    "        Doptimizer.zero_grad()\n",
    "        realDloss.backward(retain_graph=True)\n",
    "        randomnoise = torch.randn(6, nlen, device = device)\n",
    "        Gimg = G(randomnoise)\n",
    "        fake = D(Gimg.detach())\n",
    "        fakeDloss = loss(fake, torch.zeros_like(fake))\n",
    "        # -log(1-p(g(z)))\n",
    "        fakeDloss.backward()\n",
    "        dloss = realDloss + fakeDloss\n",
    "        # -(log(p(x)) + log(1-p(g(z))))\n",
    "        Doptimizer.step()\n",
    "\n",
    "        Goptimizer.zero_grad()\n",
    "        fake = D(Gimg)\n",
    "        gloss = loss(fake, torch.ones_like(fake))\n",
    "        # -log(p(g(z)))\n",
    "        gloss.backward()\n",
    "        Goptimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Dloss += dloss\n",
    "            Gloss += gloss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        D_loss.append(dloss)\n",
    "        G_loss.append(gloss)\n",
    "        D_prob.append(real)\n",
    "        G_prob.append(fake[0])\n",
    "        # print(Dloss,Gloss)\n",
    "        time_eplased = time.time() - since\n",
    "        print('Time elapsed {:.0f}m {:.0f}s)'.format(time_eplased // 60, time_eplased % 60))\n",
    "        print('epoch',epoch,'dloss',dloss,'gloss',gloss)\n",
    "        Geneimg = np.squeeze(G(randomnoise).detach().cpu().numpy())  \n",
    "        # 将数据传至cpu并显示\n",
    "        # 显示每个batchsize的前6张\n",
    "        fig = plt.figure()\n",
    "        for i in range(6):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            nimg = (Geneimg[i]+1)/2\n",
    "            plt.imshow(nimg, cmap='gray', interpolation='none')#子显示\n",
    "        plt.show()\n",
    "        showdata = Geneimg[0]\n",
    "        showda = [showdata.reshape(-1),learnTarget.reshape(-1)]\n",
    "        label = ['G(z)','x']\n",
    "        plt.hist(showda, bins = 20, label = label)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445a196-804e-4358-b581-b95710723f99",
   "metadata": {},
   "source": [
    "## 绘制G,D的损失曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ab417-863d-4e13-9854-7628aeaadcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = torch.stack(D_loss)\n",
    "G_loss = torch.stack(G_loss)\n",
    "\n",
    "plt.plot(D_loss.detach().cpu().numpy(), c = 'blue')\n",
    "plt.plot(G_loss.detach().cpu().numpy(), c = 'orange')\n",
    "plt.axhline(y = 0, ls = \":\", c = 'black')\n",
    "plt.legend(['D_loss','G_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d571875b-bb71-4dea-b1ab-6d20403ccb5f",
   "metadata": {},
   "source": [
    "## 绘制D(x),D(G(z))的概率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fc13a-64df-4c78-a0df-a983ed1e85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_prob = torch.stack(D_prob)\n",
    "G_prob = torch.stack(G_prob)\n",
    "\n",
    "plt.plot(D_prob.view(-1).detach().cpu().numpy(), c = 'blue')\n",
    "plt.plot(G_prob.view(-1).detach().cpu().numpy(), c = 'orange')\n",
    "plt.axhline(y = 0.5, ls = \":\", c = 'black')\n",
    "plt.legend(['D_prob','G_prob'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1a47a-9dad-477d-a83e-c6aa065baf94",
   "metadata": {},
   "source": [
    "## GPT示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d192df4-d1bb-41bc-8501-140788a60dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933b61b-23d6-4a3b-8266-eaae51b8984b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "# Define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.view(img.size(0), -1)\n",
    "        validity = self.model(img)\n",
    "        return validity\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = (1, 28, 28)\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# Initialize the generator and discriminator\n",
    "generator = Generator(latent_dim, img_shape)\n",
    "discriminator = Discriminator(img_shape)\n",
    "\n",
    "# Define loss function and optimizers\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1)\n",
    "        fake = torch.zeros(imgs.size(0), 1)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(imgs.size(0), latent_dim)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "\n",
    "    # Save generated images\n",
    "    if epoch % 10 == 0:\n",
    "        os.makedirs(\"image\", exist_ok=True)\n",
    "        save_image(gen_imgs.data[:25], f\"image/{epoch}.png\", nrow=5, normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bebd20-e7e7-4153-8a2d-228c347fe823",
   "metadata": {},
   "source": [
    "## 改良版num6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d4f57-20ea-4819-b5eb-498ac93b16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 优化model架构后的\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810eb48-63a1-44aa-bfd2-95be5aabdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子，保证每次运行时结果不变\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2c152-1ac8-4cf1-94ca-33ffd8be7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "# Define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.view(img.size(0), -1)\n",
    "        validity = self.model(img)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb2604-f7c0-4f40-b870-193670937cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = (1, 28, 28)\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "epochs = 300 # you can set 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e35c34-b579-4c05-8da6-f221d8b06b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0049c03-7819-48f7-9fa5-4145feddbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator and discriminator\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "generator = Generator(latent_dim, img_shape).to(device)\n",
    "discriminator = Discriminator(img_shape).to(device)\n",
    "\n",
    "# Define loss function and optimizers\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873a3d2-02ca-4685-a6cf-4c8e12bf840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "since = time.time()\n",
    "G_loss = []\n",
    "D_loss = []\n",
    "G_prob = []\n",
    "D_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3bfd0-f872-47c8-9c1b-0bebafaa45f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 先G后D\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    g_loss = 0\n",
    "    d_loss = 0\n",
    "    g_prob = 0\n",
    "    d_prob = 0\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # Adversarial ground truths\n",
    "        # valid = torch.ones(imgs.size(0), 1) \n",
    "        # fake = torch.zeros(imgs.size(0), 1)\n",
    "        imgs = imgs.to(device)\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device = device)\n",
    "        \n",
    "        gen_imgs = generator(z)\n",
    "        g_prob = discriminator(gen_imgs)\n",
    "        g_loss = adversarial_loss(g_prob, torch.ones_like(g_prob))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        d_prob = discriminator(imgs)\n",
    "        real_loss = adversarial_loss(d_prob, torch.ones_like(d_prob))\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), torch.zeros_like(d_prob))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        # Print progress\n",
    "        if i % 300 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "    \n",
    "    print(f'[Epoch{epoch}/{epochs}]')\n",
    "    time_eplased = time.time() - since\n",
    "    print('Time elapsed {:.0f}m {:.0f}s)'.format(time_eplased // 60, time_eplased % 60))\n",
    "    G_loss.append(g_loss.item())\n",
    "    D_loss.append(d_loss.item())\n",
    "    G_prob.append(g_prob[0])\n",
    "    D_prob.append(d_prob[0])\n",
    "    if epoch%10 == 0:\n",
    "        fig = plt.figure()\n",
    "        for i in range(6):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            nimg = (gen_imgs[i]+1)/2\n",
    "            plt.imshow(nimg.detach().cpu().numpy()[0], cmap='gray', interpolation='none')#子显示\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81000bff-ddfb-4d72-a3a6-17b9ed8a5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(D_loss)\n",
    "# D_loss = torch.stack(D_loss)\n",
    "# G_loss = torch.stack(G_loss)\n",
    "import numpy as np\n",
    "plt.plot(np.array(D_loss), c = 'blue')\n",
    "plt.plot(np.array(G_loss), c = 'orange')\n",
    "plt.axhline(y = 0, ls = \":\", c = 'black')\n",
    "plt.legend(['D_loss','G_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953794dd-ecbe-4892-af7c-a6fa3600237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_prob = torch.stack(D_prob)\n",
    "G_prob = torch.stack(G_prob)\n",
    "plt.plot(D_prob.view(-1).detach().cpu().numpy(), c = 'blue')\n",
    "plt.plot(G_prob.view(-1).detach().cpu().numpy(), c = 'orange')\n",
    "plt.axhline(y = 0.5, ls = \":\", c = 'black')\n",
    "plt.legend(['D_prob','G_prob'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26195f50-2b18-4aae-93d3-36d77893770c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 先D后G\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    g_loss = 0\n",
    "    d_loss = 0\n",
    "    g_prob = 0\n",
    "    d_prob = 0\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # Adversarial ground truths\n",
    "        # valid = torch.ones(imgs.size(0), 1)\n",
    "        # fake = torch.zeros(imgs.size(0), 1)\n",
    "        imgs = imgs.to(device)\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device = device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        d_prob = discriminator(imgs)\n",
    "        real_loss = adversarial_loss(d_prob, torch.ones_like(d_prob))\n",
    "        gen_imgs = generator(z)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), torch.zeros_like(d_prob))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device = device)\n",
    "        \n",
    "        gen_imgs = generator(z)\n",
    "        g_prob = discriminator(gen_imgs)\n",
    "        g_loss = adversarial_loss(g_prob, torch.ones_like(g_prob))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Print progress\n",
    "        if i % 300 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "    \n",
    "    print(f'[Epoch{epoch}/{epochs}]')\n",
    "    time_eplased = time.time() - since\n",
    "    print('Time elapsed {:.0f}m {:.0f}s)'.format(time_eplased // 60, time_eplased % 60))\n",
    "    G_loss.append(g_loss.item())\n",
    "    D_loss.append(d_loss.item())\n",
    "    G_prob.append(g_prob[0])\n",
    "    D_prob.append(d_prob[0])\n",
    "    if epoch%10 == 0:\n",
    "        fig = plt.figure()\n",
    "        for i in range(6):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            nimg = (gen_imgs[i]+1)/2\n",
    "            plt.imshow(nimg.detach().cpu().numpy()[0], cmap='gray', interpolation='none')#子显示\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ea479-625c-4002-8375-c55686cf104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(D_loss)\n",
    "# D_loss = torch.stack(D_loss)\n",
    "# G_loss = torch.stack(G_loss)\n",
    "import numpy as np\n",
    "plt.plot(np.array(D_loss), c = 'blue')\n",
    "plt.plot(np.array(G_loss), c = 'orange')\n",
    "plt.axhline(y = 0, ls = \":\", c = 'black')\n",
    "plt.legend(['D_loss','G_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29343e7a-1e3b-417b-971b-a94a8516caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_prob = torch.stack(D_prob)\n",
    "G_prob = torch.stack(G_prob)\n",
    "plt.plot(D_prob.view(-1).detach().cpu().numpy(), c = 'blue')\n",
    "plt.plot(G_prob.view(-1).detach().cpu().numpy(), c = 'orange')\n",
    "plt.axhline(y = 0.5, ls = \":\", c = 'black')\n",
    "plt.legend(['D_prob','G_prob'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521edc2-d0cf-4be3-b20a-0fa5d0076823",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存模型\n",
    "# torch.save(generator.state_dict(), './data/generator.pth')\n",
    "# torch.save(discriminator.state_dict(), './data/discriminator.pth')\n",
    "torch.save(generator, './data/ModelG.pth')\n",
    "torch.save(discriminator, './data/ModelD.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da9272d-7c62-4bda-bfd5-c279100c5aba",
   "metadata": {},
   "source": [
    "## 使用模型参数或者模型所有数据来进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d309c-e483-40b4-9d3a-99e187e08b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39564b5c-8fe6-4130-9f8a-41490b0b954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = (1, 28, 28)\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "epochs = 300 # you can set 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1f9fb-e75e-4185-90b8-ced89e331c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "# Define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.view(img.size(0), -1)\n",
    "        validity = self.model(img)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99fb03-bcf8-4388-98fc-8d3d0fa202c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd04d8-2a64-4f1f-8fb1-f54545a6559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator and discriminator\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "generator = Generator(latent_dim, img_shape).to(device)\n",
    "generator = torch.load('./data/ModelG.pth') # use model parameters and model structure\n",
    "generator.eval()\n",
    "print(generator)\n",
    "discriminator = Discriminator(img_shape).to(device)\n",
    "discriminator = torch.load('./data/ModelD.pth')\n",
    "discriminator.eval()\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea799bc7-fa0b-4e17-a6e3-2d3e38a75ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "since = time.time()\n",
    "imgs, labels = next(iter(dataloader))\n",
    "print(imgs.shape, labels[0])\n",
    "img = imgs[0][0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5f31d-36c5-49c7-83c1-821749efbf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.to(device)\n",
    "real = discriminator(imgs)\n",
    "print(real.shape)\n",
    "plt.plot(real.detach().cpu().numpy())\n",
    "plt.axhline(y = 0.5, ls = ':', color = 'gray')\n",
    "plt.show()\n",
    "import numpy as np\n",
    "print('average prob:',np.sum(real.detach().cpu().numpy())/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6dd5d-59ad-44d4-949e-d8161340a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlen = 100\n",
    "randomnoise = torch.randn(64, nlen, device = device)\n",
    "Gimg = generator(randomnoise)\n",
    "prob = discriminator(Gimg)\n",
    "prob = prob.detach().cpu().numpy()\n",
    "print(prob.shape)\n",
    "Gimg = Gimg.detach().cpu().numpy()\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.title(prob[i])\n",
    "    nimg = (Gimg[i]+1)/2\n",
    "    plt.imshow(nimg[0], cmap='gray', interpolation='none')#子显示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2522c-a0fd-4964-8534-20f6a1d5a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlen = 100\n",
    "randomnoise = torch.randn(1000, nlen, device = device)\n",
    "Gimg = generator(randomnoise)\n",
    "prob = discriminator(Gimg)\n",
    "prob = prob.detach().cpu().numpy()\n",
    "print(prob.shape)\n",
    "Gimg = Gimg.detach().cpu().numpy()\n",
    "\n",
    "num = 1\n",
    "fig = plt.figure()\n",
    "for i in range(1000):\n",
    "    plt.subplot(4,4,num)\n",
    "    plt.tight_layout()\n",
    "    if prob[i] > 0.7:\n",
    "        num = num +1\n",
    "        plt.title(prob[i])\n",
    "        nimg = (Gimg[i]+1)/2\n",
    "        plt.imshow(nimg[0], cmap='gray', interpolation='none')#子显示\n",
    "    if num > 16:\n",
    "        break\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
